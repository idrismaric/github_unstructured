{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class: \n",
    "\n",
    "1) Why can't we just use count vectorizer\n",
    "2) TF- IDF\n",
    "3) N-gram\n",
    "4) How to reduce spasrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF - IDF Score of words - Using the count vectorizer we are just trying to identify the importance of word based on the freq. This may not be a very good matrix as its just based on the freq. Thus we must try to find the importance of a words using TF-IDF score as matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>colors</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>dimension</th>\n",
       "      <th>ean</th>\n",
       "      <th>keys</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sizes</th>\n",
       "      <th>upc</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>Paperwhite voyage, no regrets!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cristina M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>One Simply Could Not Ask For More</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ricky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>Great for those that just want an e-reader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tedd Gardiner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>Love / Hate relationship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dougal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVpe7AsMilAPnD_xQ78G</td>\n",
       "      <td>B00QJDU3KY</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Amazon Devices,mazon.co.uk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-08T20:21:53Z</td>\n",
       "      <td>2017-07-18T23:52:58Z</td>\n",
       "      <td>169 mm x 117 mm x 9.1 mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kindlepaperwhite/b00qjdu3ky</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.amazon.com/Kindle-Paperwhite-High-...</td>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>I LOVE IT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miljan David Tanic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205 grams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id       asins   brand                  categories  \\\n",
       "0  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "1  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "2  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "3  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "4  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
       "\n",
       "  colors             dateAdded           dateUpdated  \\\n",
       "0    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "1    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "2    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "3    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "4    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
       "\n",
       "                  dimension  ean                         keys  ...  \\\n",
       "0  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "1  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "2  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "3  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "4  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
       "\n",
       "  reviews.rating                                 reviews.sourceURLs  \\\n",
       "0            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "1            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "2            4.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "3            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "4            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                reviews.title reviews.userCity  \\\n",
       "0              Paperwhite voyage, no regrets!              NaN   \n",
       "1           One Simply Could Not Ask For More              NaN   \n",
       "2  Great for those that just want an e-reader              NaN   \n",
       "3                    Love / Hate relationship              NaN   \n",
       "4                                   I LOVE IT              NaN   \n",
       "\n",
       "   reviews.userProvince    reviews.username  sizes upc     weight  \n",
       "0                   NaN          Cristina M    NaN NaN  205 grams  \n",
       "1                   NaN               Ricky    NaN NaN  205 grams  \n",
       "2                   NaN       Tedd Gardiner    NaN NaN  205 grams  \n",
       "3                   NaN              Dougal    NaN NaN  205 grams  \n",
       "4                   NaN  Miljan David Tanic    NaN NaN  205 grams  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets import the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Import the data\n",
    "\n",
    "df = pd.read_excel(\"/Users/amitchoudhary/Downloads/Retaildata.xlsx\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3f88bd6a4c84>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['lower_text'] = df_text['reviews.text'].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>lower_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>i am enjoying it so far. great for reading. ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>i bought one of the first paperwhites and have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>i have to say upfront - i don't like coroporat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                          lower_text  \n",
       "0  i initially had trouble deciding between the p...  \n",
       "1  allow me to preface this with a little history...  \n",
       "2  i am enjoying it so far. great for reading. ha...  \n",
       "3  i bought one of the first paperwhites and have...  \n",
       "4  i have to say upfront - i don't like coroporat...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will be working only on the reviews.text column\n",
    "\n",
    "df_text = df[['reviews.text']]\n",
    "\n",
    "# Step 1: Converting everything into a lower case\n",
    "\n",
    "df_text['lower_text'] = df_text['reviews.text'].str.lower()\n",
    "\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-4aa95cf1fab2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['clean_text'] = df_text['lower_text'].str.replace(\"[^a-z' ]\", '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>i am enjoying it so far. great for reading. ha...</td>\n",
       "      <td>i am enjoying it so far great for reading had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>i bought one of the first paperwhites and have...</td>\n",
       "      <td>i bought one of the first paperwhites and have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>i have to say upfront - i don't like coroporat...</td>\n",
       "      <td>i have to say upfront  i don't like coroporate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                          lower_text  \\\n",
       "0  i initially had trouble deciding between the p...   \n",
       "1  allow me to preface this with a little history...   \n",
       "2  i am enjoying it so far. great for reading. ha...   \n",
       "3  i bought one of the first paperwhites and have...   \n",
       "4  i have to say upfront - i don't like coroporat...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  i initially had trouble deciding between the p...  \n",
       "1  allow me to preface this with a little history...  \n",
       "2  i am enjoying it so far great for reading had ...  \n",
       "3  i bought one of the first paperwhites and have...  \n",
       "4  i have to say upfront  i don't like coroporate...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: To remove all the special character and punct. \n",
    "\n",
    "df_text['clean_text'] = df_text['lower_text'].str.replace(\"[^a-z' ]\", '')\n",
    "\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-a12e3fbde8bd>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['txt_non_stop'] = df_text['clean_text'].apply(sw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>txt_non_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "      <td>i initially had trouble deciding between the p...</td>\n",
       "      <td>initially trouble deciding paperwhite voyage r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "      <td>allow me to preface this with a little history...</td>\n",
       "      <td>allow preface little history casual reader own...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am enjoying it so far. Great for reading. Ha...</td>\n",
       "      <td>i am enjoying it so far. great for reading. ha...</td>\n",
       "      <td>i am enjoying it so far great for reading had ...</td>\n",
       "      <td>enjoying far great reading original fire since...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I bought one of the first Paperwhites and have...</td>\n",
       "      <td>i bought one of the first paperwhites and have...</td>\n",
       "      <td>i bought one of the first paperwhites and have...</td>\n",
       "      <td>bought one first paperwhites pleased constant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to say upfront - I don't like coroporat...</td>\n",
       "      <td>i have to say upfront - i don't like coroporat...</td>\n",
       "      <td>i have to say upfront  i don't like coroporate...</td>\n",
       "      <td>say upfront like coroporate hermetically close...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        reviews.text  \\\n",
       "0  I initially had trouble deciding between the p...   \n",
       "1  Allow me to preface this with a little history...   \n",
       "2  I am enjoying it so far. Great for reading. Ha...   \n",
       "3  I bought one of the first Paperwhites and have...   \n",
       "4  I have to say upfront - I don't like coroporat...   \n",
       "\n",
       "                                          lower_text  \\\n",
       "0  i initially had trouble deciding between the p...   \n",
       "1  allow me to preface this with a little history...   \n",
       "2  i am enjoying it so far. great for reading. ha...   \n",
       "3  i bought one of the first paperwhites and have...   \n",
       "4  i have to say upfront - i don't like coroporat...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  i initially had trouble deciding between the p...   \n",
       "1  allow me to preface this with a little history...   \n",
       "2  i am enjoying it so far great for reading had ...   \n",
       "3  i bought one of the first paperwhites and have...   \n",
       "4  i have to say upfront  i don't like coroporate...   \n",
       "\n",
       "                                        txt_non_stop  \n",
       "0  initially trouble deciding paperwhite voyage r...  \n",
       "1  allow preface little history casual reader own...  \n",
       "2  enjoying far great reading original fire since...  \n",
       "3  bought one first paperwhites pleased constant ...  \n",
       "4  say upfront like coroporate hermetically close...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Lets remove the stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# Create a UDF to remove the stop words\n",
    "\n",
    "def sw(x):\n",
    "    x = [word for word in x.split() if word not in stop]\n",
    "    return \" \".join(x)\n",
    "\n",
    "df_text['txt_non_stop'] = df_text['clean_text'].apply(sw)\n",
    "\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1596x7332 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 98881 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Creating a DTM\n",
    "\n",
    "# Step 4.1: Create a TF-IDF vectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# Step 6.2: We will fit this object on our txt_non_stop column of our df1\n",
    "\n",
    "tfidf_vec.fit(df_text['txt_non_stop'])\n",
    "\n",
    "# Step 6.3: Create the DTM by using fit_tranform\n",
    "\n",
    "X = tfidf_vec.fit_transform(df_text['txt_non_stop'])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tf_idf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>kindle</td>\n",
       "      <td>60.751714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>great</td>\n",
       "      <td>56.923199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>fire</td>\n",
       "      <td>53.719542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>amazon</td>\n",
       "      <td>50.044073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>like</td>\n",
       "      <td>47.763790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>sound</td>\n",
       "      <td>47.757804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6873</th>\n",
       "      <td>use</td>\n",
       "      <td>45.656608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>headphones</td>\n",
       "      <td>44.152559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>echo</td>\n",
       "      <td>41.707494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>prime</td>\n",
       "      <td>40.422549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3809</th>\n",
       "      <td>love</td>\n",
       "      <td>40.068188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367</th>\n",
       "      <td>tap</td>\n",
       "      <td>40.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>tv</td>\n",
       "      <td>36.342314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7240</th>\n",
       "      <td>would</td>\n",
       "      <td>34.642580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>speaker</td>\n",
       "      <td>34.163771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>good</td>\n",
       "      <td>33.815336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>one</td>\n",
       "      <td>33.554596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>device</td>\n",
       "      <td>33.464799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>alexa</td>\n",
       "      <td>30.953718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>tablet</td>\n",
       "      <td>30.927585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  tf_idf_score\n",
       "3533      kindle     60.751714\n",
       "2802       great     56.923199\n",
       "2423        fire     53.719542\n",
       "224       amazon     50.044073\n",
       "3695        like     47.763790\n",
       "5990       sound     47.757804\n",
       "6873         use     45.656608\n",
       "2943  headphones     44.152559\n",
       "1964        echo     41.707494\n",
       "4925       prime     40.422549\n",
       "3809        love     40.068188\n",
       "6367         tap     40.005394\n",
       "6725          tv     36.342314\n",
       "7240       would     34.642580\n",
       "6009     speaker     34.163771\n",
       "2751        good     33.815336\n",
       "4397         one     33.554596\n",
       "1646      device     33.464799\n",
       "174        alexa     30.953718\n",
       "6336      tablet     30.927585"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try to find the top 20 words based on the TF_IDF score\n",
    "\n",
    "# Lets first convert the DTM into a data frame\n",
    "\n",
    "DTM_DF = pd.DataFrame(X.toarray(), columns = tfidf_vec.get_feature_names())\n",
    "\n",
    "DTM_DF.head()\n",
    "\n",
    "# Find the freq of each words\n",
    "\n",
    "word_tfidf_score = DTM_DF.sum()\n",
    "\n",
    "\n",
    "# Lets convert the word_freq into a data frame\n",
    "\n",
    "word_df = pd.DataFrame(word_tfidf_score).reset_index()\n",
    "\n",
    "# Lets rename the column 0 as tf_idf_score\n",
    "\n",
    "word_df = word_df.rename(columns = {0 : 'tf_idf_score'})\n",
    "\n",
    "# Lets arrange the column tf_idf_score\n",
    "\n",
    "word_df.sort_values(by = 'tf_idf_score', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both count as well as the tf-idf DTM does not explain the context in which the words are used as each column of the DTM contain a single word. Such DTM are know as Unigram (1 words) DTM.\n",
    "\n",
    "We can create a DTM where each column will containg two words(pair) based on the context in which they are used within the documents as well as across the documents. Infact we can create n-gram - DTM with multiple combination of words. However, we hardly use DTM beyon trigram.\n",
    "\n",
    "Bigram DTM - Each column will have a pair of words based on the context they were used.\n",
    "\n",
    "NOTE: Whole code will remain same, only change which will happen will be in the vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1596x43389 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 125586 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Creating a Bigram TF-IDF DTM\n",
    "\n",
    "# Step 4.1: Create a TF-IDF vectorizer\n",
    "\n",
    "bigram_tfidf_vec = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Step 6.2: We will fit this object on our txt_non_stop column of our df1\n",
    "\n",
    "bigram_tfidf_vec.fit(df_text['txt_non_stop'])\n",
    "\n",
    "# Step 6.3: Create the DTM by using fit_tranform\n",
    "\n",
    "X_bigram = bigram_tfidf_vec.fit_transform(df_text['txt_non_stop'])\n",
    "\n",
    "X_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tf_idf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19232</th>\n",
       "      <td>kindle fire</td>\n",
       "      <td>20.986270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13384</th>\n",
       "      <td>fire hd</td>\n",
       "      <td>15.807135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37517</th>\n",
       "      <td>they re</td>\n",
       "      <td>14.489515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>apple buds</td>\n",
       "      <td>13.457870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>fire tv</td>\n",
       "      <td>12.766801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19762</th>\n",
       "      <td>last year</td>\n",
       "      <td>11.491784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>amazon prime</td>\n",
       "      <td>9.893368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13388</th>\n",
       "      <td>fire hdx</td>\n",
       "      <td>9.533117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20609</th>\n",
       "      <td>like they</td>\n",
       "      <td>9.014959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15435</th>\n",
       "      <td>going fall</td>\n",
       "      <td>8.971913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29777</th>\n",
       "      <td>re going</td>\n",
       "      <td>8.971913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34722</th>\n",
       "      <td>sound quality</td>\n",
       "      <td>8.715020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36928</th>\n",
       "      <td>tangle free</td>\n",
       "      <td>8.206701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28427</th>\n",
       "      <td>prime movies</td>\n",
       "      <td>8.063340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>apple tv</td>\n",
       "      <td>7.926699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33011</th>\n",
       "      <td>set headphones</td>\n",
       "      <td>7.533393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10462</th>\n",
       "      <td>early reviews</td>\n",
       "      <td>7.373355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16047</th>\n",
       "      <td>great sound</td>\n",
       "      <td>7.361096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28463</th>\n",
       "      <td>prime tv</td>\n",
       "      <td>7.276882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42711</th>\n",
       "      <td>works great</td>\n",
       "      <td>7.158168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  tf_idf_score\n",
       "19232     kindle fire     20.986270\n",
       "13384         fire hd     15.807135\n",
       "37517         they re     14.489515\n",
       "2357       apple buds     13.457870\n",
       "13480         fire tv     12.766801\n",
       "19762       last year     11.491784\n",
       "1734     amazon prime      9.893368\n",
       "13388        fire hdx      9.533117\n",
       "20609       like they      9.014959\n",
       "15435      going fall      8.971913\n",
       "29777        re going      8.971913\n",
       "34722   sound quality      8.715020\n",
       "36928     tangle free      8.206701\n",
       "28427    prime movies      8.063340\n",
       "2391         apple tv      7.926699\n",
       "33011  set headphones      7.533393\n",
       "10462   early reviews      7.373355\n",
       "16047     great sound      7.361096\n",
       "28463        prime tv      7.276882\n",
       "42711     works great      7.158168"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets try to find the top 20 words based on the TF_IDF Bigram score\n",
    "\n",
    "# Lets first convert the DTM into a data frame\n",
    "\n",
    "DTM_DF_bigram = pd.DataFrame(X_bigram.toarray(), \n",
    "                             columns = bigram_tfidf_vec.get_feature_names())\n",
    "\n",
    "DTM_DF_bigram.head()\n",
    "\n",
    "# Find the freq of each words\n",
    "\n",
    "word_tfidf_score_bigram = DTM_DF_bigram.sum()\n",
    "\n",
    "\n",
    "# Lets convert the word_freq into a data frame\n",
    "\n",
    "word_df_bigram = pd.DataFrame(word_tfidf_score_bigram).reset_index()\n",
    "\n",
    "# Lets rename the column 0 as tf_idf_score\n",
    "\n",
    "word_df_bigram = word_df_bigram.rename(columns = {0 : 'tf_idf_score'})\n",
    "\n",
    "# Lets arrange the column tf_idf_score\n",
    "\n",
    "word_df_bigram.sort_values(by = 'tf_idf_score', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 4 - 17th Sept 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word similarity using Cosine similarity - A commonly used approach to match similar words. \n",
    "\n",
    "What is cosine similarty and why is it advantageous:\n",
    "\n",
    "Cosine similarity is a matric used to determine how similar a words are. Mathematically, its measures the cosine angele between two words (represented as vector) in a multi dimensional space.\n",
    "\n",
    "The application of cosine similarity is used in google search engine along with an algo know page Rank and LexRank.\n",
    "\n",
    "We will use our bigram DTM which is converted into a data frame to find the distance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major step to find the cosine similarty between the words is to convert the DTM into a square matrix. This can take lot of time, depending upon your DTM. Thus, one good way to reduce the processing time of a square matrix, is to reduce the column in your DTM. This can be done by reducing the sparsity of your matrix. \n",
    "\n",
    "We can use arguments like min_df or max_df to reduce the sparsity of your matrix. \n",
    "\n",
    "Lets create the DTM matrix again and use these arguments to reduce sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1596x5366 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 76936 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Creating a new vector with min_df argument to reduce the number\n",
    "# of words in my DTM\n",
    "\n",
    "# Step 4.1: Create a TF-IDF vectorizer\n",
    "\n",
    "new_vec = TfidfVectorizer(ngram_range=(2,2), min_df= 0.002)\n",
    "\n",
    "# Step 4.2: We will fit this object on our txt_non_stop column of our df1\n",
    "\n",
    "new_vec.fit(df_text['txt_non_stop'])\n",
    "\n",
    "# Step 4.3: Create the DTM by using fit_tranform\n",
    "\n",
    "X_new = new_vec.fit_transform(df_text['txt_non_stop'])\n",
    "\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability create</th>\n",
       "      <th>ability expand</th>\n",
       "      <th>able browse</th>\n",
       "      <th>able compare</th>\n",
       "      <th>able hear</th>\n",
       "      <th>able increase</th>\n",
       "      <th>able ll</th>\n",
       "      <th>able open</th>\n",
       "      <th>able perform</th>\n",
       "      <th>able play</th>\n",
       "      <th>...</th>\n",
       "      <th>yet high</th>\n",
       "      <th>yet still</th>\n",
       "      <th>yet tried</th>\n",
       "      <th>youi first</th>\n",
       "      <th>younow model</th>\n",
       "      <th>youtube app</th>\n",
       "      <th>youtube hdx</th>\n",
       "      <th>youtube video</th>\n",
       "      <th>youtube videos</th>\n",
       "      <th>zero eye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability create  ability expand  able browse  able compare  able hear  \\\n",
       "0             0.0             0.0          0.0           0.0        0.0   \n",
       "1             0.0             0.0          0.0           0.0        0.0   \n",
       "2             0.0             0.0          0.0           0.0        0.0   \n",
       "3             0.0             0.0          0.0           0.0        0.0   \n",
       "4             0.0             0.0          0.0           0.0        0.0   \n",
       "\n",
       "   able increase  able ll  able open  able perform  able play  ...  yet high  \\\n",
       "0            0.0      0.0        0.0           0.0        0.0  ...       0.0   \n",
       "1            0.0      0.0        0.0           0.0        0.0  ...       0.0   \n",
       "2            0.0      0.0        0.0           0.0        0.0  ...       0.0   \n",
       "3            0.0      0.0        0.0           0.0        0.0  ...       0.0   \n",
       "4            0.0      0.0        0.0           0.0        0.0  ...       0.0   \n",
       "\n",
       "   yet still  yet tried  youi first  younow model  youtube app  youtube hdx  \\\n",
       "0        0.0        0.0         0.0           0.0          0.0          0.0   \n",
       "1        0.0        0.0         0.0           0.0          0.0          0.0   \n",
       "2        0.0        0.0         0.0           0.0          0.0          0.0   \n",
       "3        0.0        0.0         0.0           0.0          0.0          0.0   \n",
       "4        0.0        0.0         0.0           0.0          0.0          0.0   \n",
       "\n",
       "   youtube video  youtube videos  zero eye  \n",
       "0            0.0             0.0       0.0  \n",
       "1            0.0             0.0       0.0  \n",
       "2            0.0             0.0       0.0  \n",
       "3            0.0             0.0       0.0  \n",
       "4            0.0             0.0       0.0  \n",
       "\n",
       "[5 rows x 5366 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets convert the above DTM in to a data frame\n",
    "\n",
    "NEW_DTM_DF = pd.DataFrame(X_new.toarray(), \n",
    "                             columns = new_vec.get_feature_names())\n",
    "\n",
    "NEW_DTM_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find the cosine similarty between these 5366 bigram words\n",
    "\n",
    "#Step 1: To convert your DTM into a square distance matrix\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim_mat = cosine_similarity(NEW_DTM_DF.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability create</th>\n",
       "      <th>ability expand</th>\n",
       "      <th>able browse</th>\n",
       "      <th>able compare</th>\n",
       "      <th>able hear</th>\n",
       "      <th>able increase</th>\n",
       "      <th>able ll</th>\n",
       "      <th>able open</th>\n",
       "      <th>able perform</th>\n",
       "      <th>able play</th>\n",
       "      <th>...</th>\n",
       "      <th>yet high</th>\n",
       "      <th>yet still</th>\n",
       "      <th>yet tried</th>\n",
       "      <th>youi first</th>\n",
       "      <th>younow model</th>\n",
       "      <th>youtube app</th>\n",
       "      <th>youtube hdx</th>\n",
       "      <th>youtube video</th>\n",
       "      <th>youtube videos</th>\n",
       "      <th>zero eye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ability create</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability expand</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able browse</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able compare</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able hear</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ability create  ability expand  able browse  able compare  \\\n",
       "ability create             1.0             0.0          0.0           0.0   \n",
       "ability expand             0.0             1.0          0.0           0.0   \n",
       "able browse                0.0             0.0          1.0           0.0   \n",
       "able compare               0.0             0.0          0.0           1.0   \n",
       "able hear                  0.0             0.0          0.0           0.0   \n",
       "\n",
       "                able hear  able increase  able ll  able open  able perform  \\\n",
       "ability create        0.0            0.0      0.0        0.0           0.0   \n",
       "ability expand        0.0            0.0      0.0        0.0           0.0   \n",
       "able browse           0.0            1.0      0.0        0.0           0.0   \n",
       "able compare          0.0            0.0      0.0        0.0           0.0   \n",
       "able hear             1.0            0.0      0.0        0.0           0.0   \n",
       "\n",
       "                able play  ...  yet high  yet still  yet tried  youi first  \\\n",
       "ability create        0.0  ...       0.0        0.0        0.0         0.0   \n",
       "ability expand        0.0  ...       0.0        0.0        0.0         0.0   \n",
       "able browse           0.0  ...       0.0        0.0        0.0         0.0   \n",
       "able compare          0.0  ...       0.0        0.0        0.0         0.0   \n",
       "able hear             0.0  ...       0.0        0.0        0.0         0.0   \n",
       "\n",
       "                younow model  youtube app  youtube hdx  youtube video  \\\n",
       "ability create           0.0          0.0          0.0            0.0   \n",
       "ability expand           0.0          0.0          0.0            0.0   \n",
       "able browse              0.0          0.0          0.0            0.0   \n",
       "able compare             0.0          0.0          0.0            0.0   \n",
       "able hear                0.0          0.0          0.0            0.0   \n",
       "\n",
       "                youtube videos  zero eye  \n",
       "ability create             0.0       0.0  \n",
       "ability expand             0.0       0.0  \n",
       "able browse                0.0       1.0  \n",
       "able compare               0.0       0.0  \n",
       "able hear                  0.0       0.0  \n",
       "\n",
       "[5 rows x 5366 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Lets convert the sim_mat into a data frame with a row labels\n",
    "# column labels\n",
    "\n",
    "sim_df = pd.DataFrame(sim_mat, columns=NEW_DTM_DF.columns,\n",
    "                     index = NEW_DTM_DF.columns)\n",
    "\n",
    "sim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know the top 10 similar words like \"youtube app\". To do this I have to create a user define function, which will take my input word and perform the following in the above data frame: \n",
    "\n",
    "1) For a given input words, it must arrange the distance values from highest to lowest using the above data frame\n",
    "2) It must drop the input words from the final output\n",
    "3) It must than pick top N words based on the input argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets design the UDF - User define function\n",
    "\n",
    "def get_similar_words(input_word, dist_mat_df, n_words):\n",
    "    cos_vals = dist_mat_df[input_word].sort_values(ascending = False)\n",
    "    sim_words = cos_vals.drop(input_word).head(n_words)\n",
    "    return sim_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amazon giving         0.448832\n",
       "blown away            0.445475\n",
       "youtube videos        0.405603\n",
       "read amazon           0.397223\n",
       "nearly good           0.350463\n",
       "number one            0.346319\n",
       "complaint would       0.330938\n",
       "say loud              0.313366\n",
       "used use              0.306830\n",
       "considering buying    0.286679\n",
       "Name: youtube app, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_words('youtube app', sim_df, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modelling - Consider a situation in which you are confronted with large collection of documents but have no idea what they are about. One of the first things you might want to do is to classify these documents into topics or themes. \n",
    "\n",
    "What is topic modelling - In simple terms, the process of looking into a large collection of documents to identifying clusters of words and grouping them together based on a similarity and identifying the patterns in the cluster. \n",
    "\n",
    "For example: \n",
    "\n",
    "D1 = \"Sachin is a great player\"\n",
    "D2 = \"Cricket is a funny game\"\n",
    "D3 = \"Data analytics is a new career\"\n",
    "D4 = \"Data is new oil\"\n",
    "D5 = \"Titanic is a nice movie\"\n",
    "\n",
    "Based on the words in each documents, these can be divided into 3 topic. The system will just cluster D1 and D2, D3 and D4 together. However, you need understand the key words from each topic / cluster to understand what that topic is talking about. \n",
    "\n",
    "To do this, we use an algo know as LDA - Latent Dirichlet Allocation - which is a probablisitic algo. As a part of this algo, our DTM is divided into 2 sub-parts: \n",
    "\n",
    "1) Matrix between Documents and topic - This will cluster the documents under the same topic.\n",
    "2) Matrix between Topic and words - This will help you find the key words from each topic, with the help of which, you can identify what name to be given to each topic.\n",
    "\n",
    "NOTE: To find the optimal number of topics, in which your data can be divided, you need to use gridsearchCV algo. This class we will not cover gridSearch, thus we will take any number as the optimal number of topics. \n",
    "\n",
    "We will use our current DTM which is X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06153045, 0.06194082, 0.66356782, 0.15026028, 0.06270063],\n",
       "       [0.04535695, 0.04630484, 0.81652845, 0.04544298, 0.04636677],\n",
       "       [0.06193999, 0.06193867, 0.75218598, 0.06194037, 0.06199499],\n",
       "       ...,\n",
       "       [0.2       , 0.2       , 0.2       , 0.2       , 0.2       ],\n",
       "       [0.31976838, 0.45162018, 0.07471716, 0.07893718, 0.0749571 ],\n",
       "       [0.05507284, 0.35333581, 0.05868967, 0.47755536, 0.05534631]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets cluster the 1596 documents from our DTM into 5 topic\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Step 1: To build a LDA object\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=5, random_state = 1234)\n",
    "\n",
    "# Step 2: To fit this model object on our DTM\n",
    "\n",
    "lda_output = lda_model.fit_transform(X_new)\n",
    "\n",
    "lda_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lda_output will give a matrix between documents and topic. where each row will represent a document and each column will represent the topic. The cell will represent the prob. of each document to be classified in each topic.\n",
    "\n",
    "The the above array when converted into a data frame will give you 1596 row and 5 column (as we have divided our data into 5 topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4\n",
       "0  0.06  0.06  0.66  0.15  0.06\n",
       "1  0.05  0.05  0.82  0.05  0.05\n",
       "2  0.06  0.06  0.75  0.06  0.06\n",
       "3  0.05  0.05  0.05  0.41  0.43\n",
       "4  0.04  0.04  0.04  0.84  0.04"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Lets convert the lda_output into a data frame\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "doc_topic_df = pd.DataFrame(np.round(lda_output,2))\n",
    "\n",
    "doc_topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>dominate_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4  dominate_topic\n",
       "0  0.06  0.06  0.66  0.15  0.06               2\n",
       "1  0.05  0.05  0.82  0.05  0.05               2\n",
       "2  0.06  0.06  0.75  0.06  0.06               2\n",
       "3  0.05  0.05  0.05  0.41  0.43               4\n",
       "4  0.04  0.04  0.04  0.84  0.04               3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: lets find the dominating topic for each document based on the \n",
    "# highest prob.\n",
    "\n",
    "# We can use argmax command from numpy to find the index value based \n",
    "# max value for each row. \n",
    "\n",
    "dominate_topic = np.argmax(doc_topic_df.values, axis = 1)\n",
    "\n",
    "dominate_topic\n",
    "\n",
    "# Step 5: Find the number of documents in each topic\n",
    "\n",
    "doc_topic_df['dominate_topic'] = dominate_topic\n",
    "\n",
    "doc_topic_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dominate_topic</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dominate_topic    0\n",
       "0               0  323\n",
       "1               1  200\n",
       "2               2  300\n",
       "3               3  494\n",
       "4               4  279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the number of document in each topic\n",
    "\n",
    "doc_topic_df.groupby('dominate_topic').size().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 5 - 20th Sept 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a part topic modelling, we still don't know what these topics are all about. To understand what the topic is all about, we might have to study the key words in each topic. We will find top 20 words based on TF-IDF vec from each topic and then we will manually, study these words to understand what the topic is all about. \n",
    "\n",
    "Please NOTE: The LDA model can only divide the data into topics. However, it will not be able to name the topics. The name part of the topics is a human work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets understand the Topic term matrix - The topic term matrix can be extracted from the model (which in this case is lda_model) by using the argument compontent_. \n",
    "\n",
    "A topic term matrix will have (when converted to a data frame), number of rows equal to the number of topics in which the data is classified and number of columns will be equal to the number of terms. \n",
    "\n",
    "Thus for this model, the dimension of the topic term matrix will be 5 rows and 5366 columns.\n",
    "\n",
    "MOST IMPORTANT - The cells in topic term matrix contain likelihood, and thus you may see few cells value even greater than 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20000353, 0.20000553, 0.20000402, ..., 1.16397542, 1.15805286,\n",
       "        0.20000402],\n",
       "       [0.20000284, 0.51705855, 0.2000034 , ..., 0.20000263, 0.20207411,\n",
       "        0.2000034 ],\n",
       "       [0.2000031 , 0.20000482, 0.20000355, ..., 0.20020037, 0.21517392,\n",
       "        0.20000355],\n",
       "       [0.79407909, 0.20000547, 0.59860391, ..., 0.20006992, 1.48643115,\n",
       "        0.59860391],\n",
       "       [0.20000249, 0.20000388, 0.20000287, ..., 0.20004035, 0.20025245,\n",
       "        0.20000287]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see how the topic term matrix will look like\n",
    "\n",
    "lda_model.components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create the user define function to find the top 20 words from each \n",
    "# topic\n",
    "\n",
    "def show_words(vectorizer, model, n_words):\n",
    "    # Step 1: Create the array of all the words in your DTM\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    \n",
    "    # Step 2: To create and empty list\n",
    "    topic_keywords = []\n",
    "    \n",
    "    # Step 3: From my LDA model we will use the topic term matrix to find \n",
    "    # the top words based on the likelihood for each topic\n",
    "    \n",
    "    for x in lda_model.components_:\n",
    "        word_loc = (-x).argsort()[:n_words]\n",
    "        \n",
    "        # Lets append the empty list by picking the words from the \n",
    "        # keywords array\n",
    "        \n",
    "        topic_keywords.append(keywords.take(word_loc))\n",
    "    return topic_keywords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['works great', 'we ve', 'comcast ondemand', 'happy purchase',\n",
       "        'samsung note', 'ask alexa', 'fire gen', 'fire hdx',\n",
       "        'easy install', 'great addition', 'listening music',\n",
       "        'every single', 'use time', 'fire tv', 'plays music',\n",
       "        'prime member', 'ask questions', 'voice recognition',\n",
       "        'kindle fire', 'price point'], dtype='<U61'),\n",
       " array(['apple buds', 'they re', 'going fall', 're going', 'like they',\n",
       "        'would buy', 'apple tv', 'sound great', 'slightly better',\n",
       "        'full sound', 'good product', 've owned', 'people saying',\n",
       "        'bad reviews', 've purchased', 'great ve', 'better apple',\n",
       "        'items amazon', 'tablet want', 'dual speakers'], dtype='<U61'),\n",
       " array(['fire tv', 'voice search', 'amazon prime', 'fire hd', 'play music',\n",
       "        'customer service', 'google play', 'kindle fire', 'movies tv',\n",
       "        'little speaker', 'push button', 'brand new', 'love tap',\n",
       "        'prime content', 'would like', 'apple tv', 'play store',\n",
       "        'prime membership', 'works well', 'available prime'], dtype='<U61'),\n",
       " array(['great sound', 'amazon tap', 'sound quality', 'fire tv',\n",
       "        'bluetooth speaker', 'amazon echo', 'easy use', 'echo dot',\n",
       "        'great product', 'amazon fire', 'battery life', 'good sound',\n",
       "        'works great', 'easy set', 'would recommend', 'works well',\n",
       "        'around house', 'portable speaker', 'hands free', 'listen music'],\n",
       "       dtype='<U61'),\n",
       " array(['kindle fire', 'fire hd', 'tangle free', 'new kindle',\n",
       "        'set headphones', 'early reviews', 'noise cancelling', 'prime tv',\n",
       "        'magnets tangle', 'perform like', 'prime movies', 'bought gift',\n",
       "        'really like', 'going around', 'nice set', 'free cord',\n",
       "        'kindle paperwhite', 'last year', 'still hear', 'top prime'],\n",
       "       dtype='<U61')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets find the top 20 words from each topic\n",
    "\n",
    "show_words(new_vec, lda_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above words from each topic, you may want to identify what each topic is talking about. As Topic modelling have direct relationship with DTM, the more refined DTM will give a nice word combination in topcis. Thus you have to focus on three things while create Topics: \n",
    "\n",
    "1) Creation of DTM - As refine as possible.\n",
    "2) Finding the optimal number of topics in which the data can be divided - Scope of higher study\n",
    "3) Selecting the data source which have text across various products or various topics. Try to use a hetro data and not a homo data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
